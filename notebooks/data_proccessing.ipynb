{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f7c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b58239ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_essays.csv data loaded successfully.\n",
      "Total essays: 44868\n",
      "\n",
      "First 5 rows:\n",
      "                                                text  label  \\\n",
      "0  Phones\\n\\nModern humans today are always on th...      0   \n",
      "1  This essay will explain if drivers should or s...      0   \n",
      "2  Driving while the use of cellular devices\\n\\nT...      0   \n",
      "3  Phones & Driving\\n\\nDrivers should not be able...      0   \n",
      "4  Cell Phone Operation While Driving\\n\\nThe abil...      0   \n",
      "\n",
      "          prompt_name           source  RDizzl3_seven  \n",
      "0  Phones and driving  persuade_corpus          False  \n",
      "1  Phones and driving  persuade_corpus          False  \n",
      "2  Phones and driving  persuade_corpus          False  \n",
      "3  Phones and driving  persuade_corpus          False  \n",
      "4  Phones and driving  persuade_corpus          False  \n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/raw/'\n",
    "try:\n",
    "    df_train = pd.read_csv(f'{data_path}train_v2_drcat_02.csv')\n",
    "    print(\"train_essays.csv data loaded successfully.\")\n",
    "    print(f\"Total essays: {len(df_train)}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df_train.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: train_essays.csv not found in data/raw/\")\n",
    "    print(\"Please make sure you have downloaded the data and placed it in the correct folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f19bacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_whitespace(text):\n",
    "    \"\"\"\n",
    "    Function to normalize whitespace.\n",
    "    Replaces multiple whitespace chars with a single space and strips leading and trailing whilespace.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def remove_near_duplicates(df, column_name='text_cleaned'):\n",
    "    \"\"\"\n",
    "    Removes essays that are exact duplicates based on the specified column.\n",
    "    \"\"\"\n",
    "    initial_count = len(df)\n",
    "    # keep first\n",
    "    df = df.drop_duplicates(subset=[column_name], keep='first')\n",
    "    final_count = len(df)\n",
    "    print(f\"Removed {initial_count - final_count} exact duplicate essays.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0408a105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA CLEANING\n",
      "Whitespace Normalization\n",
      "Remove Dupe\n",
      "Removed 0 exact duplicate essays.\n",
      "\n",
      "Cleaned DF head:\n",
      "                                        text_cleaned  generated\n",
      "0  Phones Modern humans today are always on their...          0\n",
      "1  This essay will explain if drivers should or s...          0\n",
      "2  Driving while the use of cellular devices Toda...          0\n",
      "3  Phones & Driving Drivers should not be able to...          0\n",
      "4  Cell Phone Operation While Driving The ability...          0\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA CLEANING\")\n",
    "print(\"Whitespace Normalization\")\n",
    "df_train['text_cleaned'] = df_train['text'].apply(normalize_whitespace)\n",
    "print(\"Remove Dupe\")\n",
    "df_train = remove_near_duplicates(df_train, column_name='text_cleaned')\n",
    "if 'label' in df_train.columns:\n",
    "    df_train = df_train.rename(columns={'label': 'generated'})\n",
    "\n",
    "print(\"\\nCleaned DF head:\")\n",
    "print(df_train[['text_cleaned', 'generated']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f09bf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Statistics (for Progress Report)\n",
      "\n",
      "Class Distribution (0 = Human, 1 = LLM):\n",
      "generated\n",
      "0    27365\n",
      "1    17497\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Essay Length Statistics (in words):\n",
      "count    44862.000000\n",
      "mean       383.611966\n",
      "std        164.934406\n",
      "min          4.000000\n",
      "25%        274.000000\n",
      "50%        352.000000\n",
      "75%        451.000000\n",
      "max       1656.000000\n",
      "Name: word_count, dtype: float64\n",
      "\n",
      "Example of a Cleaned Training Sample\n",
      "\n",
      "[Human Example (label = 0)]\n",
      "Phones Modern humans today are always on their phone. They are always on their phone more than 5 hours a day no stop .All they do is text back and forward and just have group Chats on social media. They even do it while driving. They are some really bad consequences when stuff happens when it comes to a phone. Some certain areas in the United States ban phones from class rooms just because of it. When people have phones, they know about certain apps that they have .Apps like Facebook Twitter Ins...\n",
      "\n",
      "[LLM Example (label = 1)]\n",
      "In recent years, technology has had a profound impact on our daily lives and the world around us. From staying connected with loved ones to ordering food online through an app, technology has made our lives easier and more convenient. However, with great power comes great responsibility, and technology can also have negative consequences if used improperly. One example of this is the spread of misinformation through the internet. It's easy to find articles and sources that may not be accurate or...\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Statistics (for Progress Report)\")\n",
    "\n",
    "# print out class distribution\n",
    "class_counts = df_train['generated'].value_counts()\n",
    "print(\"\\nClass Distribution (0 = Human, 1 = LLM):\")\n",
    "print(class_counts)\n",
    "\n",
    "# get lengths\n",
    "df_train['word_count'] = df_train['text_cleaned'].apply(lambda x: len(x.split()))\n",
    "print(\"\\nEssay Length Statistics (in words):\")\n",
    "print(df_train['word_count'].describe())\n",
    "\n",
    "# example\n",
    "print(\"\\nExample of a Cleaned Training Sample\")\n",
    "try:\n",
    "    human_example = df_train[df_train['generated'] == 0].iloc[0]\n",
    "    print(f\"\\n[Human Example (label = 0)]\")\n",
    "    print(human_example['text_cleaned'][:500] + \"...\")\n",
    "\n",
    "    llm_example = df_train[df_train['generated'] == 1].iloc[0]\n",
    "    print(f\"\\n[LLM Example (label = 1)]\")\n",
    "    print(llm_example['text_cleaned'][:500] + \"...\")\n",
    "except IndexError:\n",
    "    print(\"\\nError: Could not find at least one example for both classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e0bbe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ada8ead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400-Token Windowing\n",
      "Original essays: 44862\n",
      "Total 400-token windows: 50996\n",
      "New class distribution (windows):\n",
      "generated\n",
      "0    33269\n",
      "1    17727\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 400 token windowing (might need change)\n",
    "print(\"400-Token Windowing\")\n",
    "W_SIZE = 400\n",
    "# overlap by 50%\n",
    "STRIDE = 200\n",
    "\n",
    "windowed_data = []\n",
    "for _, row in df_train.iterrows():\n",
    "    text = row['text_cleaned']\n",
    "    label = row['generated']\n",
    "    # tokenize by whitespace\n",
    "    tokens = text.split()\n",
    "    # use text as it is if smaller than window size\n",
    "    if len(tokens) <= W_SIZE:\n",
    "        windowed_data.append({\n",
    "            'text_window': text,\n",
    "            'generated': label\n",
    "        })\n",
    "    else:\n",
    "        for i in range(0, len(tokens) - W_SIZE + 1, STRIDE):\n",
    "            window_tokens = tokens[i : i + W_SIZE]\n",
    "            window_text = \" \".join(window_tokens)\n",
    "            windowed_data.append({\n",
    "                'text_window': window_text,\n",
    "                'generated': label\n",
    "            })\n",
    "\n",
    "df_windows = pd.DataFrame(windowed_data)\n",
    "print(f\"Original essays: {len(df_train)}\")\n",
    "print(f\"Total 400-token windows: {len(df_windows)}\")\n",
    "print(f\"New class distribution (windows):\\n{df_windows['generated'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5340f92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into train and validation sets\n",
      "total training windows: 40796\n",
      "total validation windows: 10200\n",
      "Saved to ../data/processed\n"
     ]
    }
   ],
   "source": [
    "# Train/Validation Split\n",
    "print(\"Split into train and validation sets\")\n",
    "\n",
    "# I will use 80 / 20 split (stratify for similar class balance)\n",
    "df_train_windows, df_val_windows = train_test_split(\n",
    "    df_windows,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_windows['generated']\n",
    ")\n",
    "\n",
    "print(f\"total training windows: {len(df_train_windows)}\")\n",
    "print(f\"total validation windows: {len(df_val_windows)}\")\n",
    "\n",
    "# save the result\n",
    "processed_path = '../data/processed'\n",
    "df_train_windows.to_csv(f'{processed_path}/train_windows.csv', index=False)\n",
    "df_val_windows.to_csv(f'{processed_path}/val_windows.csv', index=False)\n",
    "print(f\"Saved to {processed_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
